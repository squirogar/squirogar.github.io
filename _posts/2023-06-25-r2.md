---
layout: post
title: Explicación R2 negativo
date: 2023-06-25 20:19
description: r2 score negativo al hacer Linear Regression en scikit-learn
categories: linear-regression, python, sklearn
giscus_comments: true
related_posts: true
---

# ¿Por qué el $$R^2$$ score puede ser negativo?

De acuerdo a la [documentación de Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) el mejor score posible es 1.0. Si el $$R^2$$ es 0.0, el modelo es un modelo constante que siempre predecirá la $$y$$ promedio sin importar las inputs features. Si el score es negativo, entonces el modelo es peor que un modelo constante.

$$
R^2 = 1-\frac{\sum_{y=1}^{n}(y_i-\hat{y_i})^2}{\sum_{y=1}^{n}(y_i-\bar{y_i})^2}
$$

Los scores de `LinearRegression` de Scikit-learn usan el $$R^2$$ score. Un $$R^2$$ negativo significa que el modelo se ajustó extremadamente mal a nuestra data. Como $$R^2$$ compara el ajuste del modelo con el de la hipótesis nula (una línea recta horizontal), entonces $$R^2$$ es negativo cuando el modelo se ajusta peor que una línea horizontal. $$\bar{y}$$ es la media de todas las observaciones. Por lo tanto, un $$R^2$$ negativo significa que si alguien supiera la media de nuestro test set (y_test) y siempre la usara como "predicción", esta "predicción" sería más precisa que nuestro modelo.

En conclusión, si: 

$$\sum_{y=1}^{n}(y_i-\hat{y_i})^2 > \sum_{y=1}^{n}(y_i-\bar{y_i})^2$$

Entonces, $$R^2$$ es negativo.

Una posible solución sería escalar la data (posiblemente los targets y).

[Fuente](https://stackoverflow.com/questions/63757258/negative-accuracy-in-linear-regression)
